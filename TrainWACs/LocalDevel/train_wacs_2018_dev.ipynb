{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import codecs\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import ConfigParser\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigParser.SafeConfigParser()\n",
    "my_config = '/Users/das/work/svn/Gits/a_Projects/Projects/Infrastructure/dsg-vision/Config/default.cfg'\n",
    "with codecs.open(my_config, 'r', encoding='utf-8') as f:\n",
    "    config.readfp(f)\n",
    "\n",
    "corpora_base = config.get('DEFAULT', 'corpora_base')\n",
    "\n",
    "dsgv_home = config.get('DSGV-PATHS', 'dsgv_home')\n",
    "\n",
    "preproc_path = dsgv_home + '/Preproc/PreprocOut/'\n",
    "feats_path = dsgv_home + '/ExtractFeats/ExtractOut/'\n",
    "\n",
    "# The first features in the image feature Xs encode the region ID\n",
    "ID_FEATS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(preproc_path + 'refcoco_splits.json', 'r') as f:\n",
    "    rc_splits = json.load(f)\n",
    "    \n",
    "X = np.load(feats_path + 'mscoco_vgg19-fc2.npz')['arr_0']\n",
    "\n",
    "refcoco_refdf = pd.read_json(preproc_path + 'refcoco_refdf.json.gz',\n",
    "                         typ='frame', orient='split', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_X_by_filelist(X, filelist):\n",
    "    tmp_df = pd.DataFrame(X)\n",
    "    return np.array(tmp_df[tmp_df.iloc[:,1].isin(filelist)])\n",
    "\n",
    "def filter_refdf_by_filelist(refdf, filelist):\n",
    "    return pd.merge(refdf, pd.DataFrame(filelist, columns=['image_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = filter_X_by_filelist(X, rc_splits['train'])\n",
    "refdf_train = filter_refdf_by_filelist(refcoco_refdf, rc_splits['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word2den(refdf, refcol='refexp', regcol='region_id'):\n",
    "    '''Given refdf, returns dict of occurences (id triples) of words from expressions.'''\n",
    "    word2den = defaultdict(list)\n",
    "    for _, row in refdf.iterrows():\n",
    "        exprlist = row[refcol].split()\n",
    "        # TODO: Could take filter function that filters out some occurences.\n",
    "        #   E.g., tagger that tags whole expression & returns only the nouns.\n",
    "        for word in exprlist:\n",
    "            word_den_list = word2den[word].append((row['i_corpus'],\n",
    "                                                   row['image_id'],\n",
    "                                                   row[regcol]))\n",
    "    return {k: list(set(v)) for k,v in word2den.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.8 s, sys: 1.23 s, total: 21 s\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word2den = create_word2den(refdf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X_id_index(X, id_feats=ID_FEATS):\n",
    "    return dict(zip([tuple(e) for e in X[:,:id_feats].astype(int).tolist()], range(len(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 440 ms, sys: 626 ms, total: 1.07 s\n",
      "Wall time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_idx = make_X_id_index(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask_matrix(X, X_idx, word2den, wordlist):\n",
    "    mask_matrix = []\n",
    "    for this_word in wordlist:\n",
    "        this_word_vec = np.zeros(len(X))\n",
    "        if this_word in word2den:\n",
    "            this_word_vec[[X_idx[i] for i in word2den[this_word] if i in X_idx]] = 1\n",
    "        mask_matrix.append(this_word_vec)\n",
    "    mask_matrix = np.array(mask_matrix, dtype=bool)\n",
    "    return mask_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_matrix = make_mask_matrix(X_t, X_idx, word2den, word2den.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_for_word(X, word2den, mask_matrix, word, neg_max=None):\n",
    "    if word not in word2den:\n",
    "        #raise ValueError(\"No mask available for this word! (%s)\" % (word))\n",
    "        print \"Error!! No mask available for this word! (%s)\" % (word)\n",
    "        return None\n",
    "    this_mask = mask_matrix[word2den.keys().index(word)]\n",
    "    X_pos = X[this_mask, ID_FEATS:]\n",
    "    y_pos = np.ones(len(X_pos))\n",
    "    X_neg = X[~this_mask, ID_FEATS:]\n",
    "    # TODO: if neg_max, shuffle X_neg and limit to first neg_max rows..\n",
    "    y_neg = np.zeros(len(X_neg))\n",
    "    X_out = np.concatenate([X_pos, X_neg], axis=0)\n",
    "    y_out = np.concatenate([y_pos, y_neg])\n",
    "    return shuffle(X_out, y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_this_w, y_this_w = make_train_for_word(X_t, word2den, mask_matrix, 'cow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((166354, 4106), (166354,))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_this_w.shape, y_this_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_this_w.sum() == len(word2den['cow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = mask_matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = np.array(word2den.keys())[counts > min_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = linear_model.LogisticRegression(penalty='l1', warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    }
   ],
   "source": [
    "wacs = []\n",
    "for this_word in wordlist[:10]:\n",
    "    print \".\",\n",
    "    X_this_w, y_this_w = make_train_for_word(X_t, word2den, mask_matrix, this_word)\n",
    "    this_wac = classifier.fit(X_this_w, y_this_w)\n",
    "    wacs.append((word, this_wac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so this is where I am now:\n",
    "\n",
    "* Getting the negative examples is rather slow, because it cuts out so much of X.. Investigate whether negating mask already is slow, and if I can speed this up.\n",
    "* This presumably also makes the training slow (together with the fact that the vectors are so wide now). Investigate training in keras (and on GPU)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
